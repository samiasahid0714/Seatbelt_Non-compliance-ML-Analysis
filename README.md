# Seatbelt_Non-compliance-ML-Analysis
Data-driven analysis of seatbelt non-compliance using machine learning, SHAP-based explainability, and clustering. Identifies key risk factors and behavioral typologies from large-scale safety data. Supports evidence-based transportation safety policy and targeted interventions.

Seatbelt Non-Compliance Behavioral Analysis using Machine Learning

Overview
This project presents a data-driven behavioral safety analysis of seatbelt non-compliance using advanced machine learning and interpretable AI techniques. The study identifies key behavioral, demographic, and situational factors influencing unsafe seatbelt usage and uncovers hidden behavioral patterns among road users.
The research integrates predictive modeling, explainable AI (SHAP), and unsupervised learning to generate policy-relevant insights for transportation safety improvement. This work was accepted for presentation at ICCESD 2026.

Objectives 
• Predict seatbelt non-compliance using machine learning • Identify key factors influencing unsafe seatbelt behavior • Interpret model predictions using SHAP explainability • Discover behavioral typologies through clustering • Support data-driven road safety policy and interventions

Methodology
	1	Data Processing • Survey dataset cleaning and preprocessing • Feature engineering and encoding • Handling missing and categorical data
	2	Predictive Modeling • Random Forest Classifier for non-compliance prediction • Model evaluation using accuracy, precision, recall, F1-score
	3	Explainable AI • SHAP (SHapley Additive Explanations) used to interpret model decisions • Identification of most influential behavioral and demographic factors
	4	Behavioral Typology • Unsupervised clustering applied to identify risk-based user groups • Analysis of heterogeneous unsafe behavior patterns
  
Tools & Technologies 
• Python • Pandas, NumPy • Scikit-learn • SHAP • Matplotlib

Key Findings 
• Behavioral and situational factors strongly influence seatbelt non-compliance • Explainable AI improves transparency in safety modeling • Distinct high-risk behavioral groups exist among road users • Results support targeted safety interventions and policy design

Research Impact
This project demonstrates how machine learning + explainable AI can be applied in transportation safety research to: • Improve behavioral understanding • Enable data-driven decision making • Support evidence-based road safety policy • Address safety challenges in developing countries

Future Work 
• Deep learning for behavioral prediction • Real-time safety risk modeling • Integration with traffic and crash datasets • Policy simulation and intervention modeling
